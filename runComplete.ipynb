{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dresser.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN+3E+7HULe2fH7+JbWbhE0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hackerinheels/dresser/blob/main/us2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9tCUl1Dvitl"
      },
      "source": [
        "This is a notebook that builds a model to identify a traditional dresser against a contemporary or industrial style dresser."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEYbpdGSvuFx"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MKl1Zn30xHJ"
      },
      "source": [
        "import pathlib\n",
        "trainingdata_url = \"https://storage.googleapis.com/furndata/us.zip\"\n",
        "testdata_url = \"https://storage.googleapis.com/furndata/test.zip\"\n",
        "data_dir = tf.keras.utils.get_file(origin=trainingdata_url, \n",
        "                                   fname='us', \n",
        "                                   untar=True)\n",
        "data_dir = pathlib.Path(data_dir)\n",
        "test_data_dir = tf.keras.utils.get_file(origin=testdata_url, \n",
        "                                   fname='test', \n",
        "                                   untar=True)\n",
        "test_data_dir = pathlib.Path(test_data_dir)\n",
        "!unzip /root/.keras/datasets/us.tar.gz -d ./\n",
        "!unzip /root/.keras/datasets/test.tar.gz -d ./"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltCZq6i6slFy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e55011ca-aaf0-4e83-9691-eb18b3d85557"
      },
      "source": [
        "training_data_dir = \"/content/us/\"\n",
        "training_data_dir = pathlib.Path(training_data_dir)\n",
        "test_data_dir = \"/content/test/\"\n",
        "test_data_dir = pathlib.Path(test_data_dir)\n",
        "# First run unzip data.tar.gz\n",
        "print(len(list(training_data_dir.glob('*/*'))))\n",
        "print(len(list(test_data_dir.glob('*/*'))))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "122\n",
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6E-qp_BG2cyk"
      },
      "source": [
        "batch_size = 32\n",
        "img_height = 180\n",
        "img_width = 180"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYfBCRS72hZt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5862a433-4e0f-4778-fc08-9057dd0d4983"
      },
      "source": [
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  training_data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  labels='inferred',\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 119 files belonging to 2 classes.\n",
            "Using 96 files for training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r33VmY-HqIQP",
        "outputId": "5136b3df-7378-4c7f-b787-dcf309da282f"
      },
      "source": [
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  training_data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  labels='inferred',\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 119 files belonging to 2 classes.\n",
            "Using 23 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxmaQsmNUA7p",
        "outputId": "d880a72e-e8b7-421c-b103-1bb9cb3dfa59"
      },
      "source": [
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  test_data_dir,\n",
        "  labels='inferred',\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 9 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iz5OoGjqO6Y",
        "outputId": "db562390-27ba-412d-bda4-bbd082b7ff3b"
      },
      "source": [
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['aeshaan', 'me']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASQBs5TYqSnm"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    print(labels[i])\n",
        "    plt.title(class_names[labels[i]]+ str(labels[i].numpy()))\n",
        "    plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vs78Yut5qszI"
      },
      "source": [
        "num_classes = 2\n",
        "IMG_SIZE = 180\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.experimental.preprocessing.Resizing(IMG_SIZE, IMG_SIZE),\n",
        "  tf.keras.layers.experimental.preprocessing.Rescaling(1./255),\n",
        "  tf.keras.layers.Conv2D(16, 3, activation='relu'),\n",
        "  tf.keras.layers.MaxPool2D(),\n",
        "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "  tf.keras.layers.MaxPool2D(),\n",
        "  tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
        "  tf.keras.layers.MaxPool2D(),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SLpunqKqxmm"
      },
      "source": [
        "model.compile(\n",
        "  optimizer='adam',\n",
        "  loss=tf.losses.BinaryCrossentropy(),\n",
        "  metrics=['accuracy'])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-W-pxCHqz_9",
        "outputId": "84dc24a9-a0d0-49c0-f3c4-99df39c72ccb"
      },
      "source": [
        "model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=10\n",
        ")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "3/3 [==============================] - 9s 1s/step - loss: 1.1080 - accuracy: 0.5938 - val_loss: 0.5982 - val_accuracy: 0.7391\n",
            "Epoch 2/10\n",
            "3/3 [==============================] - 7s 1s/step - loss: 0.9183 - accuracy: 0.4792 - val_loss: 0.6202 - val_accuracy: 0.7391\n",
            "Epoch 3/10\n",
            "3/3 [==============================] - 7s 1s/step - loss: 0.6621 - accuracy: 0.5312 - val_loss: 0.7485 - val_accuracy: 0.2609\n",
            "Epoch 4/10\n",
            "3/3 [==============================] - 7s 1s/step - loss: 0.6246 - accuracy: 0.7500 - val_loss: 0.6377 - val_accuracy: 0.8261\n",
            "Epoch 5/10\n",
            "3/3 [==============================] - 7s 1s/step - loss: 0.5558 - accuracy: 0.8542 - val_loss: 0.5442 - val_accuracy: 0.7826\n",
            "Epoch 6/10\n",
            "3/3 [==============================] - 8s 1s/step - loss: 0.4555 - accuracy: 0.8958 - val_loss: 0.4960 - val_accuracy: 0.8696\n",
            "Epoch 7/10\n",
            "3/3 [==============================] - 8s 1s/step - loss: 0.3671 - accuracy: 0.8854 - val_loss: 0.3700 - val_accuracy: 0.9130\n",
            "Epoch 8/10\n",
            "3/3 [==============================] - 8s 1s/step - loss: 0.2813 - accuracy: 0.8750 - val_loss: 0.3290 - val_accuracy: 0.9130\n",
            "Epoch 9/10\n",
            "3/3 [==============================] - 7s 1s/step - loss: 0.2307 - accuracy: 0.9062 - val_loss: 0.3136 - val_accuracy: 0.8261\n",
            "Epoch 10/10\n",
            "3/3 [==============================] - 7s 1s/step - loss: 0.2200 - accuracy: 0.9062 - val_loss: 0.3078 - val_accuracy: 0.9130\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff6ae7e7f10>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nH84gHH6Wmog",
        "outputId": "94e5def0-1a52-4c8d-bae0-3a517ff22633"
      },
      "source": [
        "# Evaluate the model on the test data using `evaluate`\n",
        "print(\"Evaluate on test data\")\n",
        "results = model.evaluate(test_ds)\n",
        "print(\"test loss, test acc:\", results)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluate on test data\n",
            "1/1 [==============================] - 0s 485ms/step - loss: 0.3375 - accuracy: 1.0000\n",
            "test loss, test acc: [0.3374665677547455, 1.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0gwhSplXl0n",
        "outputId": "9c402173-5a43-44f4-8155-2d9afe872e58"
      },
      "source": [
        "# Generate predictions (probabilities -- the output of the last layer)\n",
        "# on new data using `predict`\n",
        "print(\"Generate predictions for 3 samples\")\n",
        "predictions = model.predict(test_ds)\n",
        "print(\"predictions:\\n\", predictions)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generate predictions for 3 samples\n",
            "predictions:\n",
            " [[0.35550404]\n",
            " [0.9846875 ]\n",
            " [0.45636284]\n",
            " [0.15822017]\n",
            " [0.5206408 ]\n",
            " [0.55635136]\n",
            " [0.18244395]\n",
            " [0.03290099]\n",
            " [0.27879438]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5z_d2GvHE1qy"
      },
      "source": [
        "for images, labels in test_ds.take(1):\n",
        "  predictions = model.predict(images)\n",
        "  print(predictions)\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3,3, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(class_names[labels[i]]+ str(labels[i].numpy()))\n",
        "    plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tT4ErDilCE-E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8b051b0-138c-4942-e767-d9961cdf05ff"
      },
      "source": [
        "y_true = [0,0,1,0,1,0,0,0,1]\n",
        "m = tf.keras.metrics.binary_accuracy(y_true, predictions, threshold=0.5)\n",
        "print(\"Which predictions match with binary labels:\", m.numpy())\n",
        "\n",
        "m = tf.keras.metrics.BinaryAccuracy()\n",
        "m.update_state(y_true, predictions)\n",
        "print(\"Binary Accuracy: \", m.result().numpy())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Which predictions match with binary labels: [0.6666667  0.6666667  0.6666667  0.33333334 0.6666667  0.6666667\n",
            " 0.6666667  0.33333334 0.33333334]\n",
            "Binary Accuracy:  0.5555556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRc0TUTNynJX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60aff0ea-dff6-4e97-de0f-8ff712982100"
      },
      "source": [
        "checkpoint_path = \"/content/cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Create a callback that saves the model's weights\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)\n",
        "\n",
        "# Train the model with the new callback\n",
        "model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=1,\n",
        "  callbacks=[cp_callback]\n",
        ")\n",
        "# This may generate warnings related to saving the state of the optimizer.\n",
        "# These warnings (and similar warnings throughout this notebook)\n",
        "# are in place to discourage outdated usage, and can be ignored."
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 8s 1s/step - loss: 0.1498 - accuracy: 0.9583 - val_loss: 0.3706 - val_accuracy: 0.8696\n",
            "\n",
            "Epoch 00001: saving model to /content/cp.ckpt\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff6ac1c4490>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SjInbA-zpVf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd7f80fd-32a5-4d5b-e31e-738ae19adb1f"
      },
      "source": [
        "# Loads the weights\n",
        "model.load_weights(checkpoint_path)\n",
        "\n",
        "# Re-evaluate the model\n",
        "#loss, acc = model.evaluate(test_images, test_labels, verbose=2)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f33323891d0>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-a7xjHSVtIXV"
      },
      "source": [
        "Now saving and deploying our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xIniY32tF74",
        "outputId": "9a75f416-7491-44db-a3e5-08ba234ba7a3"
      },
      "source": [
        "import tempfile\n",
        "\n",
        "MODEL_DIR = tempfile.gettempdir()\n",
        "version = 1\n",
        "export_path = os.path.join(MODEL_DIR, str(version))\n",
        "print('export_path = {}\\n'.format(export_path))\n",
        "\n",
        "tf.keras.models.save_model(\n",
        "    model,\n",
        "    export_path,\n",
        "    overwrite=True,\n",
        "    include_optimizer=True,\n",
        "    save_format=None,\n",
        "    signatures=None,\n",
        "    options=None\n",
        ")\n",
        "\n",
        "print('\\nSaved model:')\n",
        "!ls -l {export_path}"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "export_path = /tmp/1\n",
            "\n",
            "INFO:tensorflow:Assets written to: /tmp/1/assets\n",
            "\n",
            "Saved model:\n",
            "total 204\n",
            "drwxr-xr-x 2 root root   4096 Sep 30 17:37 assets\n",
            "-rw-r--r-- 1 root root  20295 Sep 30 17:37 keras_metadata.pb\n",
            "-rw-r--r-- 1 root root 178721 Sep 30 17:37 saved_model.pb\n",
            "drwxr-xr-x 2 root root   4096 Sep 30 17:37 variables\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZS0NN1eOtR9_"
      },
      "source": [
        "Examine our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkFDfv9atRPO"
      },
      "source": [
        "!saved_model_cli show --dir {export_path} --all"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lL4zMRPItcv9"
      },
      "source": [
        "import sys\n",
        "# We need sudo prefix if not on a Google Colab.\n",
        "if 'google.colab' not in sys.modules:\n",
        "  SUDO_IF_NEEDED = 'sudo'\n",
        "else:\n",
        "  SUDO_IF_NEEDED = ''"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YRkQlpG0Gnf"
      },
      "source": [
        "!echo \"deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | {SUDO_IF_NEEDED} tee /etc/apt/sources.list.d/tensorflow-serving.list && \\\n",
        "curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | {SUDO_IF_NEEDED} apt-key add -\n",
        "{SUDO_IF_NEEDED} apt update"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPuOv1op0tw7"
      },
      "source": [
        "#install the model\n",
        "!{SUDO_IF_NEEDED} apt-get install tensorflow-model-server\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gn4mgWE3udbD",
        "outputId": "78ea9587-7ff2-4240-db12-213273166a66"
      },
      "source": [
        "#Deploy the model\n",
        "import os\n",
        "os.environ[\"MODEL_DIR\"] = MODEL_DIR\n",
        "!echo \"{MODEL_DIR}\"\n",
        "!nohup tensorflow_model_server \\\n",
        "  --rest_api_port=8501 \\\n",
        "  --model_name=us_model \\\n",
        "  --model_base_path=\"/tmp\" >server.log 2>&1&\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/tmp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vets3JAXw3gO",
        "outputId": "f97580c7-88b8-438c-c94d-755b1c5075bb"
      },
      "source": [
        "\n",
        "for images, labels in test_ds.take(1):\n",
        "  test_images = images.numpy()\n",
        "  test_labels = labels.numpy()\n",
        "\n",
        "print(test_images.shape)\n",
        "print(test_labels.shape)\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(9, 180, 180, 3)\n",
            "(9,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oI5RKOWa8bt8"
      },
      "source": [
        "test_images = test_images / 255.0\n"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDDOCbxHumpB"
      },
      "source": [
        "def show(idx, title):\n",
        "  plt.figure()\n",
        "  plt.imshow(test_images[idx])\n",
        "  plt.axis('off')\n",
        "  plt.title('\\n\\n{}'.format(title), fontdict={'size': 16})\n",
        "\n",
        "import random\n",
        "rando = random.randint(0,len(test_images)-1)\n",
        "show(rando, 'An Example Image: {}'.format(class_names[test_labels[rando]]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "geiX3Ba9vfXP",
        "outputId": "4d79d247-3b04-4925-b6ae-892455bd8f16"
      },
      "source": [
        "#Create a json set\n",
        "import json\n",
        "data = json.dumps({\"signature_name\": \"serving_default\", \"instances\": test_images[0:3].tolist()})\n",
        "print('Data: {} ... {}'.format(data[:50], data[len(data)-52:]))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data: {\"signature_name\": \"serving_default\", \"instances\": ... 993164, 0.1780407428741455, 0.18980544805526733]]]]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozhXPz3IvlEI"
      },
      "source": [
        "!pip install -q requests\n",
        "\n",
        "import requests\n",
        "headers = {\"content-type\": \"application/json\"}\n",
        "json_response = requests.post('http://localhost:8501/v1/models/us_model:predict', data=data, headers=headers)\n",
        "predictions = json.loads(json_response.text)['predictions']\n",
        "\n",
        "show(0, 'The model thought this was a {} (class {}), and it was actually a {} (class {})'.format(\n",
        "  class_names[np.argmax(predictions[0])], np.argmax(predictions[0]), class_names[test_labels[0]], test_labels[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjB1DbMCvqJN"
      },
      "source": [
        "headers = {\"content-type\": \"application/json\"}\n",
        "json_response = requests.post('http://localhost:8501/v1/models/us_model/versions/1:predict', data=data, headers=headers)\n",
        "predictions = json.loads(json_response.text)['predictions']\n",
        "\n",
        "for i in range(0,3):\n",
        "  show(i, 'The model thought this was a {} (class {}), and it was actually a {} (class {})'.format(\n",
        "    class_names[np.argmax(predictions[i])], np.argmax(predictions[i]), class_names[test_labels[i]], test_labels[i]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGQykYbdKv-I"
      },
      "source": [
        "NOW Trying hyperparameterization automation using Keras Tuner with a diff model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dx5FNG7maO3z"
      },
      "source": [
        "!pip install -q -U keras-tuner"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28M1i7hELdnH"
      },
      "source": [
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.layers import BatchNormalization, experimental\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras_tuner.tuners import RandomSearch\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clB-2yxIK5Ay"
      },
      "source": [
        "# define cnn model\n",
        "def build_model_1(hp):\n",
        "\tmodel = Sequential()\n",
        "\t#model.add(experimental.preprocessing.Rescaling(1./255))\n",
        "\t#model.add(experimental.preprocessing.Resizing(256, 256))\n",
        "\thp_filters = hp.Int('filters', min_value = 32, max_value = 64, step = 32)\n",
        "\tmodel.add(Conv2D(filters=hp_filters, kernel_size=(3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(180,180, 3)))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.1))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(Dense(1, activation='softmax'))\n",
        "\t# compile model\n",
        "\t#opt = SGD(lr=0.001, momentum=0.9)\n",
        "\thp_learning_rate = hp.Choice('learning_rate', values = [1e-2, 1e-3])\n",
        "\topt = Adam(learning_rate=hp_learning_rate)#, momentum=0.9)\n",
        "\tmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\tmodel.summary()\n",
        "\treturn model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2jVyadULVhg",
        "outputId": "6ec9a858-2365-4f1b-f96e-884032a65b35"
      },
      "source": [
        "\n",
        "tuner = RandomSearch(\n",
        "    build_model_1,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=4,\n",
        "    executions_per_trial=1)\n",
        "#,\n",
        "#    directory='my_dir1') #change the directory name here  when rerunning the cell else it gives \"Oracle exit error\" \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 256, 256, 32)      896       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 256, 256, 32)      128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 128, 128, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 128, 128, 32)      9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 128, 128, 32)      128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 64, 64, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 64, 64, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 131072)            0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               16777344  \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 16,787,873\n",
            "Trainable params: 16,787,745\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wu053UGqhFg6"
      },
      "source": [
        "!\\rm -rf ./untitled_project/oracle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Rq-5iShSlqN"
      },
      "source": [
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKDFA4qrLYdd",
        "outputId": "bad2d189-ca8f-4511-b23e-39a537c5b67d"
      },
      "source": [
        "tuner.search(train_ds, validation_data=val_ds,\n",
        "  epochs=3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 4 Complete [00h 02m 03s]\n",
            "val_accuracy: 0.739130437374115\n",
            "\n",
            "Best val_accuracy So Far: 0.739130437374115\n",
            "Total elapsed time: 00h 05m 52s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxZqa9pLtxvS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6c9dbb4-d32c-4066-8dfd-6d16d8f78c48"
      },
      "source": [
        "tuner.results_summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results summary\n",
            "Results in ./untitled_project\n",
            "Showing 10 best trials\n",
            "Objective(name='val_accuracy', direction='max')\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "filters: 64\n",
            "learning_rate: 0.001\n",
            "Score: 0.739130437374115\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "filters: 32\n",
            "learning_rate: 0.001\n",
            "Score: 0.739130437374115\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "filters: 32\n",
            "learning_rate: 0.01\n",
            "Score: 0.739130437374115\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "filters: 64\n",
            "learning_rate: 0.01\n",
            "Score: 0.739130437374115\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NaUWzjMGdRPm"
      },
      "source": [
        "A few things remaining\n",
        "1. Use tuner results\n",
        "2. Add TF displayboard\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HayukWJdW8L"
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "# Load the TensorBoard notebook extension.\n",
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEc4suPLdfe9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdc0e1de-8e52-4784-8faf-0918ad9ba28d"
      },
      "source": [
        "for x, y in train_ds.take(1):\n",
        "  print(\"Shape: \", x.shape)\n",
        "  print(\"Label: \", y[0], \"->\", class_names[y[0]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape:  (32, 256, 256, 3)\n",
            "Label:  tf.Tensor(1, shape=(), dtype=int32) -> me\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKGMwM0HefhH"
      },
      "source": [
        "#Visualizing a single image\n",
        "from datetime import datetime\n",
        "import io\n",
        "import itertools\n",
        "from packaging import version\n",
        "\n",
        "# Clear out any prior log data.\n",
        "!rm -rf logs\n",
        "\n",
        "# Sets up a timestamped log directory.\n",
        "logdir = \"logs/train_data/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "# Creates a file writer for the log directory.\n",
        "file_writer = tf.summary.create_file_writer(logdir)\n",
        "\n",
        "img = x[0]\n",
        "# Using the file writer, log the reshaped image.\n",
        "with file_writer.as_default():\n",
        "  tf.summary.image(\"Training data\", x, step=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6PDdZ48fdEy"
      },
      "source": [
        "# Reshape the image for the Summary API.\n",
        "img = np.reshape(x[0], (-1, 256, 256, 3))\n",
        "with file_writer.as_default():\n",
        "  tf.summary.image(\"Training data\", img, step=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gM04LoVtg7or"
      },
      "source": [
        "!pip install tensorboard --ignore-installed\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYDkMbkCemVn"
      },
      "source": [
        "with file_writer.as_default():\n",
        "  # Don't forget to reshape.\n",
        "  tf.summary.image(\"Test data\", x, max_outputs=25, step=0)\n",
        "\n",
        "%tensorboard --logdir logs/train_data -bind_all\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
