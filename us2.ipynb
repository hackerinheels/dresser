{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dresser.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN5EbP3s+4eydja6TswgJr5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hackerinheels/dresser/blob/main/us2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9tCUl1Dvitl"
      },
      "source": [
        "This is a notebook that builds a model to identify a traditional dresser against a contemporary or industrial style dresser."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEYbpdGSvuFx"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChcNpaA9wTSB",
        "outputId": "1b466e50-11f0-4966-d1ff-e9047645d6e0"
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MKl1Zn30xHJ"
      },
      "source": [
        "import pathlib\n",
        "trainingdata_url = \"https://storage.googleapis.com/furndata/us.zip\"\n",
        "testdata_url = \"https://storage.googleapis.com/furndata/test.zip\"\n",
        "data_dir = tf.keras.utils.get_file(origin=trainingdata_url, \n",
        "                                   fname='us', \n",
        "                                   untar=True)\n",
        "data_dir = pathlib.Path(data_dir)\n",
        "test_data_dir = tf.keras.utils.get_file(origin=testdata_url, \n",
        "                                   fname='test', \n",
        "                                   untar=True)\n",
        "test_data_dir = pathlib.Path(test_data_dir)\n",
        "!unzip /root/.keras/datasets/us.tar.gz -d ./\n",
        "!unzip /root/.keras/datasets/test.tar.gz -d ./"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltCZq6i6slFy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd79ab42-f402-49c4-ecf0-658f1f112299"
      },
      "source": [
        "training_data_dir = \"/content/us/\"\n",
        "training_data_dir = pathlib.Path(training_data_dir)\n",
        "test_data_dir = \"/content/test/\"\n",
        "test_data_dir = pathlib.Path(test_data_dir)\n",
        "# First run unzip data.tar.gz\n",
        "print(len(list(training_data_dir.glob('*/*'))))\n",
        "print(len(list(test_data_dir.glob('*/*'))))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "122\n",
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6E-qp_BG2cyk"
      },
      "source": [
        "batch_size = 32\n",
        "img_height = 256\n",
        "img_width = 256"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYfBCRS72hZt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e71431a5-4c3b-4b7b-81fb-0eb099dc4da8"
      },
      "source": [
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  training_data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  labels='inferred',\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 119 files belonging to 2 classes.\n",
            "Using 96 files for training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r33VmY-HqIQP",
        "outputId": "8bcbd361-0118-4fa0-ddd4-67eb5399b644"
      },
      "source": [
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  training_data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  labels='inferred',\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 119 files belonging to 2 classes.\n",
            "Using 23 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxmaQsmNUA7p",
        "outputId": "f5d189ca-7747-4e42-cda7-a310d0bbbee6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  test_data_dir,\n",
        "  labels='inferred',\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 9 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iz5OoGjqO6Y",
        "outputId": "9822741a-2500-4ae4-e0b3-6488afb97dc8"
      },
      "source": [
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['aeshaan', 'me']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASQBs5TYqSnm"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(class_names[labels[i]])\n",
        "    plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vs78Yut5qszI"
      },
      "source": [
        "num_classes = 2\n",
        "IMG_SIZE = 256\n",
        "model = tf.keras.Sequential([\n",
        "   \n",
        "  tf.keras.layers.experimental.preprocessing.Resizing(IMG_SIZE, IMG_SIZE),\n",
        "  tf.keras.layers.experimental.preprocessing.Rescaling(1./255),\n",
        "  tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
        "  tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "  tf.keras.layers.BatchNormalization(),\n",
        "  tf.keras.layers.MaxPool2D(),\n",
        "  tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
        "  tf.keras.layers.BatchNormalization(),\n",
        "  tf.keras.layers.MaxPool2D(),\n",
        "  tf.keras.layers.Dropout(0.1),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SLpunqKqxmm"
      },
      "source": [
        "model.compile(\n",
        "  optimizer='adam',\n",
        "  loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
        "  metrics=['accuracy'])"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-W-pxCHqz_9",
        "outputId": "e9eea306-e484-4aed-f9d7-4dcaf5deb683"
      },
      "source": [
        "model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=10\n",
        ")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "3/3 [==============================] - 20s 5s/step - loss: 24.5916 - accuracy: 0.5833 - val_loss: 3.0822 - val_accuracy: 0.7391\n",
            "Epoch 2/10\n",
            "3/3 [==============================] - 18s 5s/step - loss: 24.1884 - accuracy: 0.6667 - val_loss: 3.6055 - val_accuracy: 0.7391\n",
            "Epoch 3/10\n",
            "3/3 [==============================] - 18s 5s/step - loss: 9.4289 - accuracy: 0.8021 - val_loss: 2.1684 - val_accuracy: 0.7391\n",
            "Epoch 4/10\n",
            "3/3 [==============================] - 18s 5s/step - loss: 10.7698 - accuracy: 0.7812 - val_loss: 1.0535 - val_accuracy: 0.7391\n",
            "Epoch 5/10\n",
            "3/3 [==============================] - 18s 5s/step - loss: 10.2042 - accuracy: 0.7604 - val_loss: 1.2333 - val_accuracy: 0.7826\n",
            "Epoch 6/10\n",
            "3/3 [==============================] - 18s 5s/step - loss: 5.1343 - accuracy: 0.8333 - val_loss: 1.4871 - val_accuracy: 0.7391\n",
            "Epoch 7/10\n",
            "3/3 [==============================] - 18s 5s/step - loss: 4.2159 - accuracy: 0.8438 - val_loss: 1.9568 - val_accuracy: 0.8261\n",
            "Epoch 8/10\n",
            "3/3 [==============================] - 18s 5s/step - loss: 3.5752 - accuracy: 0.8854 - val_loss: 2.0029 - val_accuracy: 0.7826\n",
            "Epoch 9/10\n",
            "3/3 [==============================] - 18s 5s/step - loss: 4.0232 - accuracy: 0.8958 - val_loss: 3.1068 - val_accuracy: 0.6087\n",
            "Epoch 10/10\n",
            "3/3 [==============================] - 18s 5s/step - loss: 3.6646 - accuracy: 0.8958 - val_loss: 6.3741 - val_accuracy: 0.6087\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2f30dec2d0>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nH84gHH6Wmog"
      },
      "source": [
        "# Evaluate the model on the test data using `evaluate`\n",
        "print(\"Evaluate on test data\")\n",
        "results = model.evaluate(test_ds)\n",
        "print(\"test loss, test acc:\", results)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0gwhSplXl0n"
      },
      "source": [
        "# Generate predictions (probabilities -- the output of the last layer)\n",
        "# on new data using `predict`\n",
        "print(\"Generate predictions for 3 samples\")\n",
        "predictions = model.predict(test_ds)\n",
        "print(\"predictions shape:\", predictions.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRc0TUTNynJX"
      },
      "source": [
        "checkpoint_path = \"/content/cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Create a callback that saves the model's weights\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)\n",
        "\n",
        "# Train the model with the new callback\n",
        "model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=1,\n",
        "  callbacks=[cp_callback]\n",
        ")\n",
        "# This may generate warnings related to saving the state of the optimizer.\n",
        "# These warnings (and similar warnings throughout this notebook)\n",
        "# are in place to discourage outdated usage, and can be ignored."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SjInbA-zpVf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd7f80fd-32a5-4d5b-e31e-738ae19adb1f"
      },
      "source": [
        "# Loads the weights\n",
        "model.load_weights(checkpoint_path)\n",
        "\n",
        "# Re-evaluate the model\n",
        "#loss, acc = model.evaluate(test_images, test_labels, verbose=2)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f33323891d0>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGQykYbdKv-I"
      },
      "source": [
        "NOW Trying hyperparameterization automation using Keras Tuner with a diff model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28M1i7hELdnH"
      },
      "source": [
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.layers import BatchNormalization, experimental\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clB-2yxIK5Ay"
      },
      "source": [
        "# define cnn model\n",
        "def build_model_1(hp):\n",
        "\tmodel = Sequential()\n",
        "\t#model.add(experimental.preprocessing.Rescaling(1./255))\n",
        "\t#model.add(experimental.preprocessing.Resizing(180, 180))\n",
        "\thp_filters = hp.Int('filters', min_value = 32, max_value = 64, step = 32)\n",
        "\tmodel.add(Conv2D(filters=hp_filters, kernel_size=(3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(180,180, 3)))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(Dropout(0.5))\n",
        "\tmodel.add(Dense(3, activation='softmax'))\n",
        "\t# compile model\n",
        "\t#opt = SGD(lr=0.001, momentum=0.9)\n",
        "\thp_learning_rate = hp.Choice('learning_rate', values = [1e-2, 1e-3])\n",
        "\topt = Adam(learning_rate=hp_learning_rate)#, momentum=0.9)\n",
        "\tmodel.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\tmodel.summary()\n",
        "\treturn model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2jVyadULVhg",
        "outputId": "6052cbcd-80c5-4479-cbe5-a38aedd93ac2"
      },
      "source": [
        "\n",
        "tuner = RandomSearch(\n",
        "    build_model_1,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=4,\n",
        "    executions_per_trial=1)\n",
        "#,\n",
        "#    directory='my_dir1') #change the directory name here  when rerunning the cell else it gives \"Oracle exit error\" \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Reloading Oracle from existing project ./untitled_project/oracle.json\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 180, 180, 32)      896       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 180, 180, 32)      128       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 180, 180, 32)      9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 180, 180, 32)      128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 90, 90, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 259200)            0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               33177728  \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 387       \n",
            "=================================================================\n",
            "Total params: 33,189,027\n",
            "Trainable params: 33,188,643\n",
            "Non-trainable params: 384\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wu053UGqhFg6"
      },
      "source": [
        "!\\rm -rf ./untitled_project/oracle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Rq-5iShSlqN"
      },
      "source": [
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKDFA4qrLYdd",
        "outputId": "f18738fd-91f0-451a-8ca4-9afabd576280"
      },
      "source": [
        "tuner.search(train_ds, validation_data=val_ds,\n",
        "  epochs=3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 3 Complete [00h 07m 07s]\n",
            "val_accuracy: 0.5220588445663452\n",
            "\n",
            "Best val_accuracy So Far: 0.5220588445663452\n",
            "Total elapsed time: 00h 17m 20s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxZqa9pLtxvS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0f279ee-f541-4c88-f431-551a44d04f69"
      },
      "source": [
        "tuner.results_summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results summary\n",
            "Results in ./untitled_project\n",
            "Showing 10 best trials\n",
            "Objective(name='val_accuracy', direction='max')\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "filters: 32\n",
            "learning_rate: 0.01\n",
            "Score: 0.5220588445663452\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "filters: 64\n",
            "learning_rate: 0.001\n",
            "Score: 0.5220588445663452\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "filters: 64\n",
            "learning_rate: 0.01\n",
            "Score: 0.41911765933036804\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adrsU4bmLgdd"
      },
      "source": [
        "train_labels = np.concatenate([y for x, y in train_ds], axis=0)\n",
        "val_labels = np.concatenate([y for x, y in val_ds], axis=0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjM05VVqMESZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75240a56-9b21-41b0-b37e-d5994fa5e205"
      },
      "source": [
        "!pip install -q -U keras-tuner"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |███▍                            | 10 kB 22.4 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 20 kB 16.5 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 30 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 40 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 51 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 61 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 71 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 81 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 92 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 97 kB 2.9 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    }
  ]
}